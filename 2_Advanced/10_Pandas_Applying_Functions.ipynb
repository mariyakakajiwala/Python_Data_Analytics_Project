{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7751281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Loading Data\n",
    "dataset = load_dataset('lukebarousse/data_jobs')\n",
    "df = dataset['train'].to_pandas()\n",
    "\n",
    "# Data Cleanup\n",
    "df['job_posted_date'] = pd.to_datetime(df['job_posted_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "276fdcf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28        109500.0\n",
       "77        140000.0\n",
       "92        120000.0\n",
       "100       228222.0\n",
       "109        89000.0\n",
       "            ...   \n",
       "785624    139216.0\n",
       "785641    150000.0\n",
       "785648    221875.0\n",
       "785682    157500.0\n",
       "785692    157500.0\n",
       "Name: salary_year_avg, Length: 22003, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[pd.notna(df['salary_year_avg'])]['salary_year_avg']\n",
    "# In the dataframe(df) I'm using the notna method of pandas to filter the 'salary_year_avg' column, and then I want it to return the salary_year_avg column as well, which is why it's been put into parenthesis a second time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d38abae",
   "metadata": {},
   "source": [
    "## Calculate Projected Salary Next Year\n",
    "This is done by applying the inflation/recession rate of the current year. \n",
    "In this case, we are going to apply the inflation rate of 3%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84410afd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method apply in module pandas.core.frame:\n",
      "\n",
      "apply(func: 'AggFuncType', axis: 'Axis' = 0, raw: 'bool' = False, result_type: \"Literal['expand', 'reduce', 'broadcast'] | None\" = None, args=(), by_row: \"Literal[False, 'compat']\" = 'compat', engine: \"Literal['python', 'numba']\" = 'python', engine_kwargs: 'dict[str, bool] | None' = None, **kwargs) method of pandas.core.frame.DataFrame instance\n",
      "    Apply a function along an axis of the DataFrame.\n",
      "    \n",
      "    Objects passed to the function are Series objects whose index is\n",
      "    either the DataFrame's index (``axis=0``) or the DataFrame's columns\n",
      "    (``axis=1``). By default (``result_type=None``), the final return type\n",
      "    is inferred from the return type of the applied function. Otherwise,\n",
      "    it depends on the `result_type` argument.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    func : function\n",
      "        Function to apply to each column or row.\n",
      "    axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      "        Axis along which the function is applied:\n",
      "    \n",
      "        * 0 or 'index': apply function to each column.\n",
      "        * 1 or 'columns': apply function to each row.\n",
      "    \n",
      "    raw : bool, default False\n",
      "        Determines if row or column is passed as a Series or ndarray object:\n",
      "    \n",
      "        * ``False`` : passes each row or column as a Series to the\n",
      "          function.\n",
      "        * ``True`` : the passed function will receive ndarray objects\n",
      "          instead.\n",
      "          If you are just applying a NumPy reduction function this will\n",
      "          achieve much better performance.\n",
      "    \n",
      "    result_type : {'expand', 'reduce', 'broadcast', None}, default None\n",
      "        These only act when ``axis=1`` (columns):\n",
      "    \n",
      "        * 'expand' : list-like results will be turned into columns.\n",
      "        * 'reduce' : returns a Series if possible rather than expanding\n",
      "          list-like results. This is the opposite of 'expand'.\n",
      "        * 'broadcast' : results will be broadcast to the original shape\n",
      "          of the DataFrame, the original index and columns will be\n",
      "          retained.\n",
      "    \n",
      "        The default behaviour (None) depends on the return value of the\n",
      "        applied function: list-like results will be returned as a Series\n",
      "        of those. However if the apply function returns a Series these\n",
      "        are expanded to columns.\n",
      "    args : tuple\n",
      "        Positional arguments to pass to `func` in addition to the\n",
      "        array/series.\n",
      "    by_row : False or \"compat\", default \"compat\"\n",
      "        Only has an effect when ``func`` is a listlike or dictlike of funcs\n",
      "        and the func isn't a string.\n",
      "        If \"compat\", will if possible first translate the func into pandas\n",
      "        methods (e.g. ``Series().apply(np.sum)`` will be translated to\n",
      "        ``Series().sum()``). If that doesn't work, will try call to apply again with\n",
      "        ``by_row=True`` and if that fails, will call apply again with\n",
      "        ``by_row=False`` (backward compatible).\n",
      "        If False, the funcs will be passed the whole Series at once.\n",
      "    \n",
      "        .. versionadded:: 2.1.0\n",
      "    \n",
      "    engine : {'python', 'numba'}, default 'python'\n",
      "        Choose between the python (default) engine or the numba engine in apply.\n",
      "    \n",
      "        The numba engine will attempt to JIT compile the passed function,\n",
      "        which may result in speedups for large DataFrames.\n",
      "        It also supports the following engine_kwargs :\n",
      "    \n",
      "        - nopython (compile the function in nopython mode)\n",
      "        - nogil (release the GIL inside the JIT compiled function)\n",
      "        - parallel (try to apply the function in parallel over the DataFrame)\n",
      "    \n",
      "          Note: Due to limitations within numba/how pandas interfaces with numba,\n",
      "          you should only use this if raw=True\n",
      "    \n",
      "        Note: The numba compiler only supports a subset of\n",
      "        valid Python/numpy operations.\n",
      "    \n",
      "        Please read more about the `supported python features\n",
      "        <https://numba.pydata.org/numba-doc/dev/reference/pysupported.html>`_\n",
      "        and `supported numpy features\n",
      "        <https://numba.pydata.org/numba-doc/dev/reference/numpysupported.html>`_\n",
      "        in numba to learn what you can or cannot use in the passed function.\n",
      "    \n",
      "        .. versionadded:: 2.2.0\n",
      "    \n",
      "    engine_kwargs : dict\n",
      "        Pass keyword arguments to the engine.\n",
      "        This is currently only used by the numba engine,\n",
      "        see the documentation for the engine argument for more information.\n",
      "    **kwargs\n",
      "        Additional keyword arguments to pass as keywords arguments to\n",
      "        `func`.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    Series or DataFrame\n",
      "        Result of applying ``func`` along the given axis of the\n",
      "        DataFrame.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    DataFrame.map: For elementwise operations.\n",
      "    DataFrame.aggregate: Only perform aggregating type operations.\n",
      "    DataFrame.transform: Only perform transforming type operations.\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    Functions that mutate the passed object can produce unexpected\n",
      "    behavior or errors and are not supported. See :ref:`gotchas.udf-mutation`\n",
      "    for more details.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> df = pd.DataFrame([[4, 9]] * 3, columns=['A', 'B'])\n",
      "    >>> df\n",
      "       A  B\n",
      "    0  4  9\n",
      "    1  4  9\n",
      "    2  4  9\n",
      "    \n",
      "    Using a numpy universal function (in this case the same as\n",
      "    ``np.sqrt(df)``):\n",
      "    \n",
      "    >>> df.apply(np.sqrt)\n",
      "         A    B\n",
      "    0  2.0  3.0\n",
      "    1  2.0  3.0\n",
      "    2  2.0  3.0\n",
      "    \n",
      "    Using a reducing function on either axis\n",
      "    \n",
      "    >>> df.apply(np.sum, axis=0)\n",
      "    A    12\n",
      "    B    27\n",
      "    dtype: int64\n",
      "    \n",
      "    >>> df.apply(np.sum, axis=1)\n",
      "    0    13\n",
      "    1    13\n",
      "    2    13\n",
      "    dtype: int64\n",
      "    \n",
      "    Returning a list-like will result in a Series\n",
      "    \n",
      "    >>> df.apply(lambda x: [1, 2], axis=1)\n",
      "    0    [1, 2]\n",
      "    1    [1, 2]\n",
      "    2    [1, 2]\n",
      "    dtype: object\n",
      "    \n",
      "    Passing ``result_type='expand'`` will expand list-like results\n",
      "    to columns of a Dataframe\n",
      "    \n",
      "    >>> df.apply(lambda x: [1, 2], axis=1, result_type='expand')\n",
      "       0  1\n",
      "    0  1  2\n",
      "    1  1  2\n",
      "    2  1  2\n",
      "    \n",
      "    Returning a Series inside the function is similar to passing\n",
      "    ``result_type='expand'``. The resulting column names\n",
      "    will be the Series index.\n",
      "    \n",
      "    >>> df.apply(lambda x: pd.Series([1, 2], index=['foo', 'bar']), axis=1)\n",
      "       foo  bar\n",
      "    0    1    2\n",
      "    1    1    2\n",
      "    2    1    2\n",
      "    \n",
      "    Passing ``result_type='broadcast'`` will ensure the same shape\n",
      "    result, whether list-like or scalar is returned by the function,\n",
      "    and broadcast it along the axis. The resulting column names will\n",
      "    be the originals.\n",
      "    \n",
      "    >>> df.apply(lambda x: [1, 2], axis=1, result_type='broadcast')\n",
      "       A  B\n",
      "    0  1  2\n",
      "    1  1  2\n",
      "    2  1  2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(df.apply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b340682f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>salary_year_avg</th>\n",
       "      <th>salary_year_inflated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>109500.0</td>\n",
       "      <td>112785.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>140000.0</td>\n",
       "      <td>144200.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>120000.0</td>\n",
       "      <td>123600.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>228222.0</td>\n",
       "      <td>235068.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>89000.0</td>\n",
       "      <td>91670.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785624</th>\n",
       "      <td>139216.0</td>\n",
       "      <td>143392.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785641</th>\n",
       "      <td>150000.0</td>\n",
       "      <td>154500.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785648</th>\n",
       "      <td>221875.0</td>\n",
       "      <td>228531.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785682</th>\n",
       "      <td>157500.0</td>\n",
       "      <td>162225.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785692</th>\n",
       "      <td>157500.0</td>\n",
       "      <td>162225.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22003 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        salary_year_avg  salary_year_inflated\n",
       "28             109500.0             112785.00\n",
       "77             140000.0             144200.00\n",
       "92             120000.0             123600.00\n",
       "100            228222.0             235068.66\n",
       "109             89000.0              91670.00\n",
       "...                 ...                   ...\n",
       "785624         139216.0             143392.48\n",
       "785641         150000.0             154500.00\n",
       "785648         221875.0             228531.25\n",
       "785682         157500.0             162225.00\n",
       "785692         157500.0             162225.00\n",
       "\n",
       "[22003 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we are craeting this function to then apply it to the salary_year_avg column of df so that all the NaN values in this column will be replaced with the projected salary (with the 3% inflation rate)\n",
    "df_salary = df[pd.notna(df['salary_year_avg'])].copy()\n",
    "\n",
    "def projected_salary(salary): #this is where the function starts\n",
    "    return salary * 1.03\n",
    "\n",
    "df_salary['salary_year_inflated'] = df_salary['salary_year_avg'].apply(projected_salary)\n",
    "\n",
    "df_salary[['salary_year_avg', 'salary_year_inflated']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8582bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>salary_year_avg</th>\n",
       "      <th>salary_year_inflated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>109500.0</td>\n",
       "      <td>112785.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>140000.0</td>\n",
       "      <td>144200.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>120000.0</td>\n",
       "      <td>123600.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>228222.0</td>\n",
       "      <td>235068.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>89000.0</td>\n",
       "      <td>91670.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785624</th>\n",
       "      <td>139216.0</td>\n",
       "      <td>143392.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785641</th>\n",
       "      <td>150000.0</td>\n",
       "      <td>154500.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785648</th>\n",
       "      <td>221875.0</td>\n",
       "      <td>228531.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785682</th>\n",
       "      <td>157500.0</td>\n",
       "      <td>162225.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785692</th>\n",
       "      <td>157500.0</td>\n",
       "      <td>162225.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22003 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        salary_year_avg  salary_year_inflated\n",
       "28             109500.0             112785.00\n",
       "77             140000.0             144200.00\n",
       "92             120000.0             123600.00\n",
       "100            228222.0             235068.66\n",
       "109             89000.0              91670.00\n",
       "...                 ...                   ...\n",
       "785624         139216.0             143392.48\n",
       "785641         150000.0             154500.00\n",
       "785648         221875.0             228531.25\n",
       "785682         157500.0             162225.00\n",
       "785692         157500.0             162225.00\n",
       "\n",
       "[22003 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here, we are writing the same code as above but with an anonymous/lambda function\n",
    "df_salary['salary_year_inflated'] = df_salary['salary_year_avg'].apply(lambda salary: salary * 1.03)\n",
    "# in the above lambda function, I am naming the variable as 'salary'\n",
    "df_salary[['salary_year_avg', 'salary_year_inflated']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cac4c863",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>salary_year_avg</th>\n",
       "      <th>salary_year_inflated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>109500.0</td>\n",
       "      <td>112785.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>140000.0</td>\n",
       "      <td>144200.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>120000.0</td>\n",
       "      <td>123600.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>228222.0</td>\n",
       "      <td>235068.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>89000.0</td>\n",
       "      <td>91670.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785624</th>\n",
       "      <td>139216.0</td>\n",
       "      <td>143392.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785641</th>\n",
       "      <td>150000.0</td>\n",
       "      <td>154500.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785648</th>\n",
       "      <td>221875.0</td>\n",
       "      <td>228531.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785682</th>\n",
       "      <td>157500.0</td>\n",
       "      <td>162225.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785692</th>\n",
       "      <td>157500.0</td>\n",
       "      <td>162225.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22003 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        salary_year_avg  salary_year_inflated\n",
       "28             109500.0             112785.00\n",
       "77             140000.0             144200.00\n",
       "92             120000.0             123600.00\n",
       "100            228222.0             235068.66\n",
       "109             89000.0              91670.00\n",
       "...                 ...                   ...\n",
       "785624         139216.0             143392.48\n",
       "785641         150000.0             154500.00\n",
       "785648         221875.0             228531.25\n",
       "785682         157500.0             162225.00\n",
       "785692         157500.0             162225.00\n",
       "\n",
       "[22003 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# u can also rewrite it as follows:\n",
    "df_salary['salary_year_inflated'] = df_salary['salary_year_avg'] * 1.03\n",
    "\n",
    "df_salary[['salary_year_avg', 'salary_year_inflated']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6ee1f044",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Data\n",
    "dataset = load_dataset('lukebarousse/data_jobs')\n",
    "df = dataset['train'].to_pandas()\n",
    "\n",
    "# Data Cleanup\n",
    "df['job_posted_date'] = pd.to_datetime(df['job_posted_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "365654fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df['job_skills'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d450c923",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "malformed node or string: ['r', 'python', 'sql', 'nosql', 'power bi', 'tableau']",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[50]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mast\u001b[39;00m \u001b[38;5;66;03m#the ast module stands for Abstract Syntax Trees and it's a part of the Python Standard Library\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mast\u001b[49m\u001b[43m.\u001b[49m\u001b[43mliteral_eval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mjob_skills\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Dell\\anaconda3\\envs\\python_course\\Lib\\ast.py:110\u001b[39m, in \u001b[36mliteral_eval\u001b[39m\u001b[34m(node_or_string)\u001b[39m\n\u001b[32m    108\u001b[39m                 \u001b[38;5;28;01mreturn\u001b[39;00m left - right\n\u001b[32m    109\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _convert_signed_num(node)\n\u001b[32m--> \u001b[39m\u001b[32m110\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_convert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode_or_string\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Dell\\anaconda3\\envs\\python_course\\Lib\\ast.py:109\u001b[39m, in \u001b[36mliteral_eval.<locals>._convert\u001b[39m\u001b[34m(node)\u001b[39m\n\u001b[32m    107\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    108\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m left - right\n\u001b[32m--> \u001b[39m\u001b[32m109\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_convert_signed_num\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Dell\\anaconda3\\envs\\python_course\\Lib\\ast.py:83\u001b[39m, in \u001b[36mliteral_eval.<locals>._convert_signed_num\u001b[39m\u001b[34m(node)\u001b[39m\n\u001b[32m     81\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     82\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m - operand\n\u001b[32m---> \u001b[39m\u001b[32m83\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_convert_num\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Dell\\anaconda3\\envs\\python_course\\Lib\\ast.py:74\u001b[39m, in \u001b[36mliteral_eval.<locals>._convert_num\u001b[39m\u001b[34m(node)\u001b[39m\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_convert_num\u001b[39m(node):\n\u001b[32m     73\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(node, Constant) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(node.value) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mcomplex\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m         \u001b[43m_raise_malformed_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m node.value\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Dell\\anaconda3\\envs\\python_course\\Lib\\ast.py:71\u001b[39m, in \u001b[36mliteral_eval.<locals>._raise_malformed_node\u001b[39m\u001b[34m(node)\u001b[39m\n\u001b[32m     69\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m lno := \u001b[38;5;28mgetattr\u001b[39m(node, \u001b[33m'\u001b[39m\u001b[33mlineno\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m     70\u001b[39m     msg += \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m on line \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlno\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m71\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg + \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnode\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mValueError\u001b[39m: malformed node or string: ['r', 'python', 'sql', 'nosql', 'power bi', 'tableau']"
     ]
    }
   ],
   "source": [
    "import ast #the ast module stands for Abstract Syntax Trees and it's a part of the Python Standard Library\n",
    "\n",
    "ast.literal_eval(df['job_skills'][1])\n",
    "#this is returning an error bec my job_skills col is already a list and i obviously can't convert a list into a list using ast.literal_eval\n",
    "#ast.literal_eval is meant to convert a str to a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fdc22dd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df['job_skills'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a8e820",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[53]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m        \u001b[38;5;28;01mreturn\u001b[39;00m ast.literal_eval(skill_list)  \u001b[38;5;66;03m#this gives a value error because there are None values in this column and the ast.literal_eval function doesn't/can't apply to None values.\u001b[39;00m\n\u001b[32m      5\u001b[39m                                             \u001b[38;5;66;03m#to prevent the value error, we are writing the if statement.\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33mjob_skills\u001b[39m\u001b[33m'\u001b[39m] = \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mjob_skills\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclean_list\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Dell\\anaconda3\\envs\\python_course\\Lib\\site-packages\\pandas\\core\\series.py:4924\u001b[39m, in \u001b[36mSeries.apply\u001b[39m\u001b[34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[39m\n\u001b[32m   4789\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mapply\u001b[39m(\n\u001b[32m   4790\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   4791\u001b[39m     func: AggFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m   4796\u001b[39m     **kwargs,\n\u001b[32m   4797\u001b[39m ) -> DataFrame | Series:\n\u001b[32m   4798\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   4799\u001b[39m \u001b[33;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[32m   4800\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   4915\u001b[39m \u001b[33;03m    dtype: float64\u001b[39;00m\n\u001b[32m   4916\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m   4917\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4918\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   4919\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4920\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4921\u001b[39m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[43m=\u001b[49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4922\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4923\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m-> \u001b[39m\u001b[32m4924\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Dell\\anaconda3\\envs\\python_course\\Lib\\site-packages\\pandas\\core\\apply.py:1427\u001b[39m, in \u001b[36mSeriesApply.apply\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1424\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.apply_compat()\n\u001b[32m   1426\u001b[39m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1427\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Dell\\anaconda3\\envs\\python_course\\Lib\\site-packages\\pandas\\core\\apply.py:1507\u001b[39m, in \u001b[36mSeriesApply.apply_standard\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1501\u001b[39m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[32m   1502\u001b[39m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[32m   1503\u001b[39m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[32m   1504\u001b[39m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[32m   1505\u001b[39m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[32m   1506\u001b[39m action = \u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj.dtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1507\u001b[39m mapped = \u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1508\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m=\u001b[49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[32m   1509\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1511\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[32m0\u001b[39m], ABCSeries):\n\u001b[32m   1512\u001b[39m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[32m   1513\u001b[39m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[32m   1514\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m obj._constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index=obj.index)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Dell\\anaconda3\\envs\\python_course\\Lib\\site-packages\\pandas\\core\\base.py:921\u001b[39m, in \u001b[36mIndexOpsMixin._map_values\u001b[39m\u001b[34m(self, mapper, na_action, convert)\u001b[39m\n\u001b[32m    918\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[32m    919\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m arr.map(mapper, na_action=na_action)\n\u001b[32m--> \u001b[39m\u001b[32m921\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m=\u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Dell\\anaconda3\\envs\\python_course\\Lib\\site-packages\\pandas\\core\\algorithms.py:1743\u001b[39m, in \u001b[36mmap_array\u001b[39m\u001b[34m(arr, mapper, na_action, convert)\u001b[39m\n\u001b[32m   1741\u001b[39m values = arr.astype(\u001b[38;5;28mobject\u001b[39m, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   1742\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1743\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1745\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m lib.map_infer_mask(\n\u001b[32m   1746\u001b[39m         values, mapper, mask=isna(values).view(np.uint8), convert=convert\n\u001b[32m   1747\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mlib.pyx:2972\u001b[39m, in \u001b[36mpandas._libs.lib.map_infer\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[53]\u001b[39m\u001b[32m, line 3\u001b[39m, in \u001b[36mclean_list\u001b[39m\u001b[34m(skill_list)\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mclean_list\u001b[39m(skill_list):\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m pd.notna(skill_list):\n\u001b[32m      4\u001b[39m        \u001b[38;5;28;01mreturn\u001b[39;00m ast.literal_eval(skill_list)\n",
      "\u001b[31mValueError\u001b[39m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "# u cannot run the ast.literal_eval function on an entire column. so u create a function for it instead as shown below:\n",
    "def clean_list(skill_list):\n",
    "    if pd.notna(skill_list):\n",
    "       return ast.literal_eval(skill_list)  #this gives a value error because there are None values in this column and the ast.literal_eval function doesn't/can't apply to None values.\n",
    "                                            #to prevent the value error, we are writing the if statement.\n",
    "\n",
    "df['job_skills'] = df['job_skills'].apply(clean_list)\n",
    "\n",
    "#this should've worked according to the video but it didn't since my skill_list is already a list, so pd.notna() tries to apply itself to each item inside the list, returning an array of True/False values — and Python doesn’t know how to evaluate that as a single if condition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7ff6b9",
   "metadata": {},
   "source": [
    "The stuff done below is the solution given by Chat GPT to the above error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fd25f688",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "def clean_list(skill_list):\n",
    "    if isinstance(skill_list, list):\n",
    "        return skill_list\n",
    "    elif isinstance(skill_list, str):\n",
    "        try:\n",
    "            return ast.literal_eval(skill_list)\n",
    "        except:\n",
    "            return []\n",
    "    else:\n",
    "        return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "258ce4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['job_skills'] = df['job_skills'].apply(clean_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e1d6218e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "0                                                   []\n",
      "1           [r, python, sql, nosql, power bi, tableau]\n",
      "2    [python, sql, c#, azure, airflow, dax, docker,...\n",
      "3    [python, c++, java, matlab, aws, tensorflow, k...\n",
      "4    [bash, python, oracle, aws, ansible, puppet, j...\n",
      "Name: job_skills, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(type(df['job_skills'][0]))  # Should be <class 'list'>\n",
    "print(df['job_skills'].head())   # Should show actual lists like ['python', 'sql']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77db237b",
   "metadata": {},
   "source": [
    "Going back to everything done in the video:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3a37e3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an empty array is ambiguous. Use `array.size > 0` to check that an array is not empty.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[57]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33mjob_skills\u001b[39m\u001b[33m'\u001b[39m] = \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mjob_skills\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mskill_list\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mast\u001b[49m\u001b[43m.\u001b[49m\u001b[43mliteral_eval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mskill_list\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnotna\u001b[49m\u001b[43m(\u001b[49m\u001b[43mskill_list\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mskill_list\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Dell\\anaconda3\\envs\\python_course\\Lib\\site-packages\\pandas\\core\\series.py:4924\u001b[39m, in \u001b[36mSeries.apply\u001b[39m\u001b[34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[39m\n\u001b[32m   4789\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mapply\u001b[39m(\n\u001b[32m   4790\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   4791\u001b[39m     func: AggFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m   4796\u001b[39m     **kwargs,\n\u001b[32m   4797\u001b[39m ) -> DataFrame | Series:\n\u001b[32m   4798\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   4799\u001b[39m \u001b[33;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[32m   4800\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   4915\u001b[39m \u001b[33;03m    dtype: float64\u001b[39;00m\n\u001b[32m   4916\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m   4917\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4918\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   4919\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4920\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4921\u001b[39m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[43m=\u001b[49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4922\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4923\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m-> \u001b[39m\u001b[32m4924\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Dell\\anaconda3\\envs\\python_course\\Lib\\site-packages\\pandas\\core\\apply.py:1427\u001b[39m, in \u001b[36mSeriesApply.apply\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1424\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.apply_compat()\n\u001b[32m   1426\u001b[39m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1427\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Dell\\anaconda3\\envs\\python_course\\Lib\\site-packages\\pandas\\core\\apply.py:1507\u001b[39m, in \u001b[36mSeriesApply.apply_standard\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1501\u001b[39m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[32m   1502\u001b[39m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[32m   1503\u001b[39m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[32m   1504\u001b[39m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[32m   1505\u001b[39m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[32m   1506\u001b[39m action = \u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj.dtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1507\u001b[39m mapped = \u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1508\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m=\u001b[49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[32m   1509\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1511\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[32m0\u001b[39m], ABCSeries):\n\u001b[32m   1512\u001b[39m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[32m   1513\u001b[39m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[32m   1514\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m obj._constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index=obj.index)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Dell\\anaconda3\\envs\\python_course\\Lib\\site-packages\\pandas\\core\\base.py:921\u001b[39m, in \u001b[36mIndexOpsMixin._map_values\u001b[39m\u001b[34m(self, mapper, na_action, convert)\u001b[39m\n\u001b[32m    918\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[32m    919\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m arr.map(mapper, na_action=na_action)\n\u001b[32m--> \u001b[39m\u001b[32m921\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m=\u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Dell\\anaconda3\\envs\\python_course\\Lib\\site-packages\\pandas\\core\\algorithms.py:1743\u001b[39m, in \u001b[36mmap_array\u001b[39m\u001b[34m(arr, mapper, na_action, convert)\u001b[39m\n\u001b[32m   1741\u001b[39m values = arr.astype(\u001b[38;5;28mobject\u001b[39m, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   1742\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1743\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1745\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m lib.map_infer_mask(\n\u001b[32m   1746\u001b[39m         values, mapper, mask=isna(values).view(np.uint8), convert=convert\n\u001b[32m   1747\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mlib.pyx:2972\u001b[39m, in \u001b[36mpandas._libs.lib.map_infer\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[57]\u001b[39m\u001b[32m, line 1\u001b[39m, in \u001b[36m<lambda>\u001b[39m\u001b[34m(skill_list)\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33mjob_skills\u001b[39m\u001b[33m'\u001b[39m] = df[\u001b[33m'\u001b[39m\u001b[33mjob_skills\u001b[39m\u001b[33m'\u001b[39m].apply(\u001b[38;5;28;01mlambda\u001b[39;00m skill_list: ast.literal_eval(skill_list) \u001b[38;5;28;01mif\u001b[39;00m pd.notna(skill_list) \u001b[38;5;28;01melse\u001b[39;00m skill_list)\n",
      "\u001b[31mValueError\u001b[39m: The truth value of an empty array is ambiguous. Use `array.size > 0` to check that an array is not empty."
     ]
    }
   ],
   "source": [
    "df['job_skills'] = df['job_skills'].apply(lambda skill_list: ast.literal_eval(skill_list) if pd.notna(skill_list) else skill_list)\n",
    "#this is just a way to do the same thing using lambda. It's obviously giving me an error bec my skill_list was alraedy a list. so it's giving me the same error as i got before using chatgpt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f08fa8",
   "metadata": {},
   "source": [
    "## Calculate Projected Salary Next Year\n",
    "Now we are going to use the apply method on a row (earlier we used it on a column - job_skills).\n",
    "- Here we are assuming the following:\n",
    "  - Senior roles assume 5%\n",
    "  - Other roles assume 3%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763481fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_salary['salary_year_inflated'] = df_salary['salary_year_avg'].apply(lambda salary: salary * 1.03)\n",
    "\n",
    "df_salary[['salary_year_avg', 'salary_year_inflated']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925cecb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title_short</th>\n",
       "      <th>salary_year_avg</th>\n",
       "      <th>salary_year_inflated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>109500.0</td>\n",
       "      <td>112785.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>140000.0</td>\n",
       "      <td>144200.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>120000.0</td>\n",
       "      <td>123600.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>228222.0</td>\n",
       "      <td>235068.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>89000.0</td>\n",
       "      <td>91670.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785624</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>139216.0</td>\n",
       "      <td>143392.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785641</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>150000.0</td>\n",
       "      <td>154500.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785648</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>221875.0</td>\n",
       "      <td>228531.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785682</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>157500.0</td>\n",
       "      <td>162225.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785692</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>157500.0</td>\n",
       "      <td>162225.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22003 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       job_title_short  salary_year_avg  salary_year_inflated\n",
       "28      Data Scientist         109500.0             112785.00\n",
       "77       Data Engineer         140000.0             144200.00\n",
       "92       Data Engineer         120000.0             123600.00\n",
       "100     Data Scientist         228222.0             235068.66\n",
       "109       Data Analyst          89000.0              91670.00\n",
       "...                ...              ...                   ...\n",
       "785624   Data Engineer         139216.0             143392.48\n",
       "785641   Data Engineer         150000.0             154500.00\n",
       "785648  Data Scientist         221875.0             228531.25\n",
       "785682  Data Scientist         157500.0             162225.00\n",
       "785692  Data Scientist         157500.0             162225.00\n",
       "\n",
       "[22003 rows x 3 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def projected_salary(row):\n",
    "    if'Senior' in row['job_title_short']:\n",
    "        return 1.05 * row['salary_year_avg']   #u can put all this code in a lambda function as well.\n",
    "    else:\n",
    "        return 1.03 * row['salary_year_avg']\n",
    "\n",
    "df_salary['salary_year_inflated'] = df_salary.apply(projected_salary, axis=1)\n",
    "\n",
    "df_salary[['job_title_short', 'salary_year_avg', 'salary_year_inflated']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
